{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import wave, math, contextlib\n",
    "import speech_recognition as sr\n",
    "from moviepy.editor import AudioFileClip\n",
    "from better_profanity import profanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import tensorflow \n",
    "import keras\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"seaborn\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_video(video_file_path, SEQUENCE_LENGTH):\n",
    " \n",
    "    video_reader = cv2.VideoCapture(video_file_path)\n",
    " \n",
    "    # Get the width and height of the video.\n",
    "    original_video_width = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    original_video_height = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    " \n",
    "    # Declare a list to store video frames we will extract.\n",
    "    frames_list = []\n",
    "    \n",
    "    # Store the predicted class in the video.\n",
    "    predicted_class_name = ''\n",
    " \n",
    "    # Get the number of frames in the video.\n",
    "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    " \n",
    "    # Calculate the interval after which frames will be added to the list.\n",
    "    skip_frames_window = max(int(video_frames_count/SEQUENCE_LENGTH),1)\n",
    " \n",
    "    # Iterating the number of times equal to the fixed length of sequence.\n",
    "    for frame_counter in range(SEQUENCE_LENGTH):\n",
    " \n",
    "        # Set the current frame position of the video.\n",
    "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
    " \n",
    "        success, frame = video_reader.read() \n",
    " \n",
    "        if not success:\n",
    "            break\n",
    " \n",
    "        # Resize the Frame to fixed Dimensions.\n",
    "        resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "        \n",
    "        # Normalize the resized frame.\n",
    "        normalized_frame = resized_frame / 255\n",
    "        \n",
    "        # Appending the pre-processed frame into the frames list\n",
    "        frames_list.append(normalized_frame)\n",
    " \n",
    "    from PIL import Image\n",
    "    from numpy import asarray\n",
    "    \n",
    "    if \".jpg\" in video_file_path:\n",
    "        print(video_file_path)\n",
    "        img = cv2.imread(video_file_path)\n",
    "\n",
    "        frames_list.clear();\n",
    "\n",
    "        for i in range(16):\n",
    "            resized_frame = cv2.resize(img, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "            normalized_frame = resized_frame / 255\n",
    "            frames_list.append(normalized_frame)\n",
    "        \n",
    " \n",
    "\n",
    "    # Passing the  pre-processed frames to the model and get the predicted probabilities.\n",
    "    predicted_labels_probabilities = MoBiLSTM_model.predict(np.expand_dims(frames_list, axis = 0))[0]\n",
    " \n",
    "    # Get the index of class with highest probability.\n",
    "    predicted_label = np.argmax(predicted_labels_probabilities)\n",
    " \n",
    "    # Get the class name using the retrieved index.\n",
    "    predicted_class_name = CLASSES_LIST[predicted_label]\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    # Display the predicted class along with the prediction confidence.\n",
    "    print(f'Predicted: {predicted_class_name} \\nConfidence: {predicted_labels_probabilities[predicted_label]}')\n",
    "        \n",
    "    video_reader.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Predicted: Violence \n",
      "Confidence: 0.655598521232605\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "IMAGE_HEIGHT , IMAGE_WIDTH = 64, 64\n",
    "SEQUENCE_LENGTH = 16\n",
    "DATASET_DIR = \"./Real Life Violence Dataset/\"\n",
    "CLASSES_LIST = [\"NonViolence\",\"Violence\"]\n",
    "input_video_file_path = \"./validation.mp4\"\n",
    "MoBiLSTM_model=load_model('model.h5')\n",
    "predict_video(input_video_file_path, 16)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ee22ea2ff98dcee3fcbbb538ef93435e54ac360d8d2b54b72db674010ff1c30a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
